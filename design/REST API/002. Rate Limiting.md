# Basic Idea
We need rate limiting because of **security reason.**

Let's say we can upload 20 videos per day and have two instances having uploading API.

✅We should implment a rate limiter as kind of shared service.

<img src="https://storage.googleapis.com/zenn-user-upload/d2839a2c31d7-20230601.png" width="500px" />

When the rate limit has been reached, tell users that they are **throttled.**<br>
・スロットルは、一定の閾値を超えた場合に通信量を意図的に抑制する制御のこと。<br>
・なので"throttle"という動詞は「**閾値超えたので通信量一旦抑えます**」という意味。

<img src="https://storage.googleapis.com/zenn-user-upload/b11b252dfc38-20230601.png" width="500px" />

# Non-functional requirement
## Latency
✅We want to pretend like the rate limiter doesn't even exist so that latency is super low. <br>
　 **Rate limiterを仲介することでLatencyに影響は与えたくない。Rate limiterは存在しないくらいの扱いにしたい。**

Quick reads and writes leads to less latency... so<br>
🔴Preventing reading from disk(rules) can make it faster by placing cache.<br>
　→ Rules won't be updated frequently.

<img src="https://storage.googleapis.com/zenn-user-upload/10b9245c7216-20230602.png" width="500px" />

## Availability
**Fail-Open**
Something in our system goes down, our entire system including the apis should **function as if the rate limiter never existed.**

**Fail-Closed**
Something in our system goes down, our entire system basically goes down and tell a user internal server error 500.

# High Level Design
✅Rate Limit server acts like a reverse proxy.
1. Store and read rules in persistent storage.
2. Store and read counts in in-memory key-value store.
3. Navitate requests to endpoints if the rate limit is not over.

※APIごとに異なるRuleを適用したい -> StorageにRuleを定義＆使うときに取得する。<br>
※Rule（ruleId: xxxx, targetApi: xxxxx, timeUnit: 秒/分, alg: xxxxx, maxRequests: 1000)

<img src="https://storage.googleapis.com/zenn-user-upload/852b1fb269ac-20230602.png" width="500px" />

# Detailed Design
## Algorithm
|Algorithm|Description|
|----|----|
|Fixed Window|△less accurate, ○less cost-intensive.|
|Sliding Window|○more accurate, △more cost-intensive.|
|Token Bucket||
|Sliding Window Counter|a balance between fixed window and sliding window|
### Fixed Window
・Disregard the previous fixed window.<br>
・1秒間の中でカウントだけしてればいい。次周期に入ったらカウントをリセット<br>
　= 各リクエストのTimestampを記録しておく必要はない。

1秒間の中で100リクエストまで、という発想。<br>
なので<br>
・0.9 - 1.0秒 の間に100リクエスト<br>
・1.0 - 1.1秒 の間に100リクエスト<br>
つまり**0.2秒間に200リクエストがあっても、各1秒間で100リクエストが収まってる**ので、OKとなる。

<img src="https://storage.googleapis.com/zenn-user-upload/52b6feea72d0-20230602.png" width="500px" />

↓ What would be a better algorithm that would be more accurate?

### Sliding Window
・Check the requests unti the last 1 minitues = shift window

<img src="https://storage.googleapis.com/zenn-user-upload/23581372bd1e-20230602.png" width="500px" />

△ We have to store the exact timestamp for each request.

🔴Can be implmented by **Redis Sorted-Set**
　→ ソート基準となるスコアにTimestampを利用すればOK。

https://redis.io/docs/data-types/sorted-sets/

### Token Bucket

### Sliding Window Counter

# scaling in-memory store horizontally
We have to navigate requests to the same in-memory store every single time... how can we accomplish? -> **Consistent Hashing**
